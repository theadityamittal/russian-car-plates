# Plateâ€Component Classification Pipeline

A twoâ€stage workflow for extracting features from licenseâ€plate data, exploratory analysis, and building a baseline classification model using CatBoost (and friends).

---

## ğŸš€ Project Workflow

1. **Data Exploration & Feature Engineering**  
   - Extract raw plate components  
   - Inspect distributions, correlations, missingness  
   - Build new features (e.g. length, characterâ€type ratios, region codes)  
   - See `data_exploration.ipynb`

2. **Automated Column Detection & Modeling**  
   - Load the engineered dataset  
   - Automatically identify numeric vs. categorical columns  
   - Train and evaluate baseline classifiers (LightGBM, XGBoost, CatBoost)  
   - Inspect logs and metrics in `catboost_info/`  
   - See `data_modeling.ipynb`

3. **Generate Submission**  
   - Apply your bestâ€performing model to `test.csv`  
   - Write predictions to `submission.csv`  

---

## ğŸ“‚ Repository Structure

```

.
â”œâ”€â”€ catboost\_info/                # CatBoost training artifacts & logs
â”‚   â”œâ”€â”€ catboost\_training.json
â”‚   â”œâ”€â”€ learn/
â”‚   â”‚   â””â”€â”€ events.out.tfevents   # TensorBoard logs
â”‚   â”œâ”€â”€ learn\_error.tsv           # perâ€iteration error
â”‚   â”œâ”€â”€ time\_left.tsv             # ETA per iteration
â”‚   â””â”€â”€ tmp/                      # intermediate CatBoost files
â”œâ”€â”€ data/                         # raw & processed datasets + helpers
â”‚   â”œâ”€â”€ processed\_train.pkl       # after feature engineering
â”‚   â”œâ”€â”€ processed\_test.pkl
â”‚   â”œâ”€â”€ supplemental\_english.py   # languageâ€specific helpers
â”‚   â”œâ”€â”€ supplemental\_russian.py
â”‚   â”œâ”€â”€ train.csv                 # raw training data
â”‚   â”œâ”€â”€ test.csv                  # raw test data
â”œâ”€â”€ data\_exploration.ipynb        # featureâ€engineering & EDA
â”œâ”€â”€ data\_modeling.ipynb           # automated column detection & modeling
â”œâ”€â”€ submission.csv                # your final predictions
â””â”€â”€ README.md                     # this file

````

---

## ğŸ¤– Installation & Setup

1. **Clone the repository**  
   ```bash
   git clone https://github.com/theadityamittal/russian-car-plates.git
   cd russian-car-plates
   ````

2. **Create & activate a virtual environment**

   ```bash
   python3 -m venv venv
   source venv/bin/activate
   ```

3. **Install dependencies**

   ```bash
   pip install -r requirements.txt
   ```

   If there is no `requirements.txt`, install manually:

   ```bash
   pip install numpy pandas scikit-learn lightgbm xgboost catboost jupyter matplotlib
   ```

---

## â–¶ï¸ Usage

1. **Launch Jupyter**

   ```bash
   jupyter notebook
   ```

2. **Run Notebooks in Order**

   * **`data_exploration.ipynb`**

     * Cleans and merges raw CSVs
     * Generates `processed_train.pkl` & `processed_test.pkl` in `data/`
   * **`data_modeling.ipynb`**

     * Reads the processed pickles
     * Autoâ€detects column types
     * Trains CatBoost (and optionally LightGBM/XGBoost)
     * Saves logs under `catboost_info/`
     * Outputs predictions to `submission.csv`

---

## ğŸ“ˆ Outputs & Artifacts

* **`data/processed_*.pkl`**: engineered features
* **`catboost_info/`**: training logs, metrics, and TensorBoard events
* **`submission.csv`**: your final predictions in â€œID,labelâ€ format

---

## ğŸ“„ Data Description

* **`train.csv` / `test.csv`**: raw license-plate strings, target labels
* **`supplemental_{english,russian}.py`**: helper functions for languageâ€specific parsing

---

## ğŸ¤ Contributing

* Feel free to open an issue to discuss improvements
* Submit pull requests for bug fixes, new feature ideas, or clearer documentation

---

## ğŸ“œ License

This project is released under the MIT License.

